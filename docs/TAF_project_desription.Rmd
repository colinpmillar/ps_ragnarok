---
title: Transparent Assessment Framework (TAF)
output:
  html_vignette:
    toc: true
    toc_depth: 2
    number_sections: true
    mathjax: null
---

<!-- ![](http://www.ices.dk/_layouts/15/1033/images/icesimg/iceslogo.png "ICES") -->

<br>

# Summary

* ...


<br>

# Project Background

## ICES stock assessment current working practices

* Working groups, benchmarks, update assessments
* Input, model, output
* Sharepoint, report, stock annex, graphs



<br>

# Project Overview / Description

## Core issues to address

* Hard to find data
* Hard to rerun model
* Sharepoint files are not directly accessible

## Percieved benefits

* transparency
* reproduceability
* improved quality
* time efficiency?
* protection against loss of "institutional memory"

## Project design guide

* "empty desk scenario": with only internet access anyone can rerun a stock assessment.
* encapsulated framework
* use existing procedures and processes
* reliable and simple

## constraints

* deliver in 2 years

## Difficulties

* buy in by stock assessors
* issues with ownership of assessments and process
* the variety of approaches
* who implements updates to procedures e.g at benchmark

# Aim

*To implement a system that will give stock assessors the tools to archive their methods, data and results, so that they can
replicated at a future date and also be rerun the following year with minimal changes*

<br>

# Objectives

## Archive of All Stock Assessments

* All ICES assessments in one place
* Data-limited stocks may be included as well

## Accessible Online

* Open read access
* Write access on a per user basis

## Rerun Assessment Online

* Computational server runs models
* Old assessments can be run as well

## Interfacing with Other ICES Services

* Pass input from DATRAS and Intercatch to TAF
* Pass output from TAF to stock assessment graphs

## Reliable and Simple

* System should be as simple as possible
* Some desired functionality will be sacrificed
* The system must still work if/when Arni & Colin leave


<br>

# Scope

## The system **will**
* work for all stock assessment
* allow assessments to be rerun quickly and automatically
* allow alternative assessments to be archived (i.e. allow multple assessment runs)
* provide a way to track changes in input data from year to year
* provide a way to track changes in assessment scripts from year to year
* require experts to use R in thier stock assessments

## The system **will not**
* archive user code for ad-hoc analyses

## The system **might**
* allow users to work from their own hard drives
* allow users to use different analysis software?


<br>

# Evaluation Criteria

## ...








<br>

# Design

## Web Server

* All interaction with the user is through a website
* Main interactions are: upload input data, run model, provide output
* Output is provided in two formats: online browsing and read directly
* More advanced features: validate data/results, compare data/results

## Computational Server

* The machine that runs assessment models
* Needs to be able to run a wide variety of models
* Requires access to uploaded data, executable programs, and scripts
* Model output will be stored in a dedicated area

## Archives Accessible Online

* Final input data for each assessment
* Scripts that were used in each assessment
* Model executable that was used in each assessment
* Output from each assessment

## Minimize Mouse Clicks

* User interface should involve as few mouse clicks as possible
* This allows data to flow between programs, and supports scripting
* Feedback from informal user surveys has focused on this point


<br>

# Workflow options

## Fist time use

* Upload final input data to input database
* write script to read data from input database
* write script to do data manipulation
* write script to run model (define executable etc.)
* write script to write output into a standard format
* test scripts on user PC
* upload scripts to stock folder (code archive)
* click *run model*
* check input data and results
* click *finalise assessment* to archive the assessment

## Update assessment

* Upload final input data to input database
* download working directory structure
* amend script to read data from input database
* amend script to do data manipulation
* test scripts on user PC
* upload scripts to stock folder (code archive)
* click *run model*
* check input data and results
* click *finalise assessment* to archive the assessment

## Rerun assessment

* click *run model*
* check input data and results



<br>

# Implementation

## Web Server

* Apache is the world's most used web server software
* The simple [data.hafro.is](http://data.hafro.is) is just HTTP and CSV\
  (this directory tree is transparent, easy to maintain and use)


## Build on Stable Technologies

* Apache is the world's most used web server software
* The simple [data.hafro.is](http://data.hafro.is) is just HTTP and CSV\
  (this directory tree is transparent, easy to maintain and use)
* The successful [stockassessment.org](http://stockassessment.org) uses
  makefiles\
  (a makefile implements the flow of input->model->output)
* R scripts are already used by many to organize their stock assessments

## Virtual Machines

* Some models run only in Linux, while some run only in Windows
* Therefore, the web interface will probably have two buttons:\
  `Run makefile in Linux`\
  `Run makefile in Windows`
* These buttons would invoke separate virtual machines

## Library of Platforms and Models

* Some models run in R, some are ADMB applications, etc.
* Some only run in older versions of R, ADMB, etc.
* Therefore, the system should provide many versions ready to run
* One frozen version of R (with pkgs) could be defined for each year

<br>


# Deliverables

## Input database

* Implement a database of validated quality controlled input data that can be read online

## Output database

* implement a database of standard outputs from final stock assessment runs

## Code archive

* Develop an archive of code used to run stock assessments that is accessible online

## Methods (tools) archive

* develop an archive of computational tools (to be available on line?)

## Computational Server

* Implement a linux server that can run R scripts, run executables, access the web
* Implement a windows server that can run R scripts, run executables, access the web

## Web access to Computational server

* implement a user interface on a webserver and show on the sharepoint (http://taf.ices.dk/)




<br>

# Timeline and Milestones

## Web Server (Experimental)

* Step 1: server showing a simple message on a webpage
* Step 2: server providing a directory tree of CSV files
* Step 3: server that allows users to upload data
* Step 4: server that runs a makefile

## Test Cases

* `linreg`: linear regression that reads input data and writes output
* `adsep`: Icelandic saithe, a basic ADSEP model run
* `gadget`: Icelandic tusk, a basic Gadget model run
* `sam`: Icelandic saithe, a basic SAM model run
* `tsa`: Scottish cod in 6a, a basic TSA model run

## Web Server (Operational)

* Step 5: server that maintains all files inside Git version control
* Step 6: server with early user interface

## Deployment

* First new assessment, working closely with a stock coordinator
* First WG, with extensive support from the Secretariat

## Web Server (Full)

* Step 7: complete user interface, based on feedback from first WG
* Step 8: other improvements, as needed


<br>

# Resources required

## Servers

* Computational server running linux
* Computational server running windows
* Web server
* Data server

## databases / Archives

* Input database
* Output database
* code archive
* methods / executable archive

## Services

* webservices to DATRAS
* webservices to Intercatch
* webservices to RDB
* access to output database by standard graphs




